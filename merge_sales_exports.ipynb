{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c83d1f8-0a82-4760-bdd8-cae5e54572f1",
   "metadata": {},
   "source": [
    "### Общее описание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a739e46-db8e-470d-b889-9aa62c277ee5",
   "metadata": {},
   "source": [
    "Данная тетрадка используются для объединения различных `.csv` файлов в единый нормализованный датафрейм.\\\n",
    "Почему это нужно? Зачастую выгрузка поступает в виде разрозненных файлов (в этом примере это будут продажи за каждый месяц), которые нужно объединить в один для дальнейшего анализа."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b82cab4-1a15-416b-8e36-9240423cc766",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4600cac1-5f78-48eb-a445-e93bc9af2b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем основные библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Для работы с системным окружением\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3a1f4b-408a-469a-8a34-f53280385ddb",
   "metadata": {},
   "source": [
    "## 1 Загрузка и обработка датасетов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd99e6-bf25-4a6b-805a-4a028503d319",
   "metadata": {},
   "source": [
    "## 1.1 Загрузка файлов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c87ae-0a29-4d57-9755-d8c0fa8ec454",
   "metadata": {},
   "source": [
    "Определяем путь к текущей рабочей директории.\\\n",
    "Также предварительно указываем папку в переменной ``, в которой хранятся наши `.csv` файлы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eefeeb4-ef9c-44cc-b716-4f151ed38b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наименование папки с выгрузками\n",
    "data_folder = 'Выгрузка_продажи'\n",
    "\n",
    "# Путь к текущей рабочей директории\n",
    "work_dir = Path.cwd()\n",
    "\n",
    "# Создаем переменную с расположение файлов выгрузок\n",
    "data_dir = work_dir / data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66263e8a-d724-4d55-a250-338e0b4229cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список объектов Path с файлами выгрузок\n",
    "csv_files = list(data_dir.glob(\"*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b3d5d5-4d1c-4de5-8c09-45a93f94a384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 44 файла:\n",
      "2022_10_выгрузка\n",
      "2022_11_выгрузка\n",
      "2022_12_выгрузка\n",
      "2022_1_выгрузка\n",
      "2022_2_выгрузка\n",
      "2022_3_выгрузка\n",
      "2022_4_выгрузка\n",
      "2022_5_выгрузка\n",
      "2022_6_выгрузка\n",
      "2022_7_выгрузка\n",
      "2022_8_выгрузка\n",
      "2022_9_выгрузка\n",
      "2023_10_выгрузка\n",
      "2023_11_выгрузка\n",
      "2023_12_выгрузка\n",
      "2023_1_выгрузка\n",
      "2023_2_выгрузка\n",
      "2023_3_выгрузка\n",
      "2023_4_выгрузка\n",
      "2023_5_выгрузка\n",
      "2023_6_выгрузка\n",
      "2023_7_выгрузка\n",
      "2023_8_выгрузка\n",
      "2023_9_выгрузка\n",
      "2024_10_выгрузка\n",
      "2024_11_выгрузка\n",
      "2024_12_выгрузка\n",
      "2024_1_выгрузка\n",
      "2024_2_выгрузка\n",
      "2024_3_выгрузка\n",
      "2024_4_выгрузка\n",
      "2024_5_выгрузка\n",
      "2024_6_выгрузка\n",
      "2024_7_выгрузка\n",
      "2024_8_выгрузка\n",
      "2024_9_выгрузка\n",
      "2025_1_выгрузка\n",
      "2025_2_выгрузка\n",
      "2025_3_выгрузка\n",
      "2025_4_выгрузка\n",
      "2025_5_выгрузка\n",
      "2025_6_выгрузка\n",
      "2025_7_выгрузка\n",
      "2025_8_выгрузка\n"
     ]
    }
   ],
   "source": [
    "# Распаковываем и выводим список файлов, чтобы убедить что все определилось\n",
    "print(f\"Найдено {len(csv_files)} файла:\")\n",
    "print(*[f.stem for f in csv_files], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d85bf615-9fc9-435a-b08f-3404129c08dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем пустой список, в котором будут храниться датафреймы\n",
    "df_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b54fb2-d9fe-4907-945c-e1aefae8d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Т.к. файлов много, то читаем файлы в цикле\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            file,\n",
    "            engine='python',\n",
    "            sep='\\t',\n",
    "            thousands='\\xa0',\n",
    "            decimal=','\n",
    "        )\n",
    "        # (!!!) Позже в этом месте будет функция по нормализации каждого датафрейма\n",
    "        df_list.append(df) # Присоединяем результат к списку\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при чтении файла {file.name}: {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5c8d5-8743-4e68-b125-df84d335f023",
   "metadata": {},
   "source": [
    "## 1.2 Нормализация отдельных датафреймов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0853a8cb-d689-42c0-aa4a-11a6556a744d",
   "metadata": {},
   "source": [
    "В связи с особенностями выгрузок в **1С** данные приведены в искаженном виде: присутствуеют лишние строк заголовок (группировки полей), а также строки отдельных группировок создают пустую строку.\\\n",
    "Ниже действия по очистке таблиц от таких строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8cea356-5b7f-4fb2-9d51-aa358c2a69c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для создания маски фильтра по полю `Номенклатура`\n",
    "def nomenclature_mask(df):\n",
    "    \n",
    "    # Задаем условие 1: поле 'Номенклатура' не пустое\n",
    "    condition_1 = df['Номенклатура'].notna() & (df['Номенклатура'] != '')\n",
    "\n",
    "    # Условие 2: 'Номенклатура' НЕ содержится в значении df['Номенклатура']\n",
    "    condition_2 = ~df['Номенклатура'].astype(str).str.contains('Номенклатура', na=False)\n",
    "\n",
    "    # Возвращаем готовую маску\n",
    "    return condition_1 & condition_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bce9ae27-8ac9-472b-b672-f8c70dd2385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем поля с категориями типов в пределах которых и будет осуществляться сдвиг\n",
    "category_columns = ['Тип_1', 'Тип_2', 'Тип_3', 'Тип_4', 'Тип_5', 'Тип_6', 'Тип_7', 'Тип_8']\n",
    "\n",
    "# Определяем числовые поля\n",
    "cols_purpose = ['Количество', 'Сумма продажи', 'Прибыль']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03e4f15f-2f85-4f2f-a15d-f1edad4ea51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для сдвига названий групп товаров влево\n",
    "def left_shift_groups(df):\n",
    "    \n",
    "    # Получаем подматрицу с нужными колонками\n",
    "    data = df[category_columns].to_numpy()\n",
    "\n",
    "    # Создаём маску валидных значений (не NaN и не пустая строка)\n",
    "    valid_mask = (~pd.isna(data)) & (data != '')\n",
    "\n",
    "    # Создаём пустой макет массива для заполнения результатом.\n",
    "    result = np.full(data.shape, None, dtype=object)\n",
    "\n",
    "    # Построчный сдвиг\n",
    "    for i in range(data.shape[0]):\n",
    "        # Создаем список, содержащий только валидные значения\n",
    "        valid_values = data[i, valid_mask[i]]\n",
    "        # Вставляем их в макет (вставляется слева направо)\n",
    "        result[i, :len(valid_values)] = valid_values\n",
    "\n",
    "    # Обновляем датафрейм значениями полученной матрицы\n",
    "    df.loc[:, category_columns] = result\n",
    "    \n",
    "    # Возвращаем обновленный датафрейм\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe45520a-4882-411a-b9c4-88531ebe9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для очистки строк по признаку `Номенклатура`\n",
    "def clear_rows_by_nomenclature(df, i):\n",
    "    '''\n",
    "    Предварительно сохраняет ключевые суммы для последующего сравнения\n",
    "    со значениям после обработки датафрейма (чтобы убедиться, что данные не изменились)\n",
    "    '''\n",
    "    # В выгрузке 1С итоговые суммы в последней строке\n",
    "    df_sum_before = df.iloc[-1][cols_purpose]\n",
    "    \n",
    "    '''\n",
    "    В этой части датафрейм фильтруется по маске, получемой в отдельной функции: удаляеется N-ая\n",
    "    (чаще вторая) строка с 1С, которая отвечает за группировку в \"шапке\", которая приводит к\n",
    "    появлению лишней строки. Также удаляются строки с пустой номенклатурой, - это строки шапок\n",
    "    \"подгруппировок\" (в этом примере - столбца периода).\n",
    "    '''\n",
    "    df = df[nomenclature_mask]\n",
    "\n",
    "    '''\n",
    "    Далее необходимо \"сдвинуть\" содержимое колонок с наименования групп товаров, т.к. в 1С они изначально\n",
    "    идут смещенными вправо, из-за чего нельзя выполнить корректную группировку по этому признаку.\n",
    "    '''\n",
    "    # Обновляем датафрейм значениями полученной матрицы\n",
    "    df = left_shift_groups(df)\n",
    "\n",
    "    '''\n",
    "    Убедимся что ключевые суммы не изменились после всех изменений:\n",
    "    '''\n",
    "    df_sum_after = df[cols_purpose].sum()\n",
    "\n",
    "    # Задаем допуски сравнения. В выгрузке могут присутствовать мусорные записи\n",
    "    tolerance = {\n",
    "        cols_purpose[0]: 1e-3,\n",
    "        cols_purpose[1]: 1e-2,\n",
    "        cols_purpose[2]: 1e-2\n",
    "    }\n",
    "    # Сраниваем суммы по заданным полям\n",
    "    check_sums = all(\n",
    "        np.isclose(\n",
    "            df_sum_before[column], df_sum_after[column], rtol=0, atol=tolerance[column]\n",
    "        ) for column in cols_purpose\n",
    "    )\n",
    "        \n",
    "    if not check_sums:\n",
    "        # Если суммы в каком-то датафрейме не сходятся\n",
    "        print(f\"❌ Не сходятся суммы в {csv_files[i].stem} ❌\")\n",
    "        print(\"До преобразований:\")\n",
    "        print(df_sum_before.to_dict())\n",
    "        print(\"После:\")\n",
    "        print(df_sum_after.to_dict())\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"✅ {csv_files[i].stem}\")\n",
    "        print(\"До преобразований:\")\n",
    "        print(df_sum_before.to_dict())\n",
    "        print(\"После:\")\n",
    "        print(df_sum_after.to_dict())\n",
    "        print()\n",
    "        # Возвращаем результат\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f91387c-f2a6-4ff6-ab24-71af3a73ab4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# с нумерацией с 1\n",
    "df_list = [clear_rows_by_nomenclature(df, i) for i, df in enumerate(df_list, start=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0079991e-bf71-4b2f-8c1e-af49ae72fd86",
   "metadata": {},
   "source": [
    "## 1.3 Объединение датафреймов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502cdb4b-2a2a-4d34-b3d3-94b37d531f59",
   "metadata": {},
   "source": [
    "Объединяем полученные списком датафреймы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea775dc5-da69-46c2-a273-a753d62d372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Склеиваем датафреймы\n",
    "df = pd.concat(\n",
    "    df_list,\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b6e990-cb14-4c07-9a13-4c2653638930",
   "metadata": {},
   "source": [
    "## 1.4 Работа с данными (при необходимости)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a069a-ba70-4834-97aa-b8ed7a363708",
   "metadata": {},
   "source": [
    "### 1.4.1 Приведение типов данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3588e27-817f-4f08-b415-c362988c87f9",
   "metadata": {},
   "source": [
    "Для корректного работы с датой, а также во избежание ошибок при сохранении этого поля, приведем столбец `` к типо `datetime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b4a7bef-9f9e-43b6-a111-36d26d0aac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим поле к типу datetime\n",
    "df['Период, месяц'] = pd.to_datetime(\n",
    "    df['Период, месяц'],\n",
    "    format='%d.%m.%Y %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a335a-6caa-43da-ac51-bd200a27482a",
   "metadata": {},
   "source": [
    "Другие поля также можно было бы привести к категориальным или строковым типам данных, но в рамках этих задач это не имеет смысла, т.к. не сказывается ни на быстродействии, ни на размере файлов.\\\n",
    "Наименования полей также остаются без изменения, чтобы оставались понятными при необходимости загрузки `csv` в Excel для операторов 1С."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c8d3b-7126-47d6-a66d-7a45e01c992e",
   "metadata": {},
   "source": [
    "### 1.4.2 Удаление лишних групп товаров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f25bca-479d-4371-98d4-dfd7dce02028",
   "metadata": {},
   "source": [
    "В текущем примере идет подготовка данных для прогнозирования продаж и прибыли.\\\n",
    "Для этих целей нам необходимо исключить некоторые группы товаров из учета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "139e67be-223f-4e5a-bfa6-8a83f8936634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ФРУКТЫ, ОВОЩИ', 'АЛКОГОЛЬ', 'УЦЕНКА/СПИСАНИЕ НЕКОНДИЦИИ',\n",
       "       'ЛИШНЕЕ', 'ПИВО И СЛ/А НАПИТ', 'ТАБАЧНЫЕ ИЗДЕЛИЯ (4СЕКЦИЯ)',\n",
       "       'ЗАМОРОЖЕННЫЕ ПРОДУКТЫ', 'КОНСЕРВАЦИЯ', 'БЫТОВАЯ ХИМИЯ',\n",
       "       'СРЕДСТВА ГИГИЕНЫ', 'КОСМЕТИКА, ПАРФЮМЕРИЯ', 'КАССА', 'NON FOOD',\n",
       "       'ДЕТСКОЕ ПИТАНИЕ', 'МАЙОНЕЗЫ,КЕТЧУПЫ,СОУСЫ', 'БАКАЛЕЯ',\n",
       "       'ТАЛНАХСКАЯ 22 ПОСТОРОННИЕ ПОСТАВЩИКИ',\n",
       "       '24 СОБСТВЕННОЕ ПРОИЗВОДСТВО (СПК) (5 СЕКЦИЯ)',\n",
       "       'ОХЛАЖДЕННЫЕ ПРОДУКТЫ', 'МОЛОЧНЫЕ ПРОДУКТЫ',\n",
       "       'СНЭКИ,СУХОФРУКТЫ,ОРЕХИ', 'РЫБНЫЙ ГАСТРОНОМ И ПРЕСЕРВЫ', 'ПЕКАРНЯ',\n",
       "       'МЯСНОЙ ГАСТРОНОМ', 'ДИЕТИЧЕСКИЕ ПРОДУКТЫ', 'КОНДИТЕРСКИЕ ИЗДЕЛИЯ',\n",
       "       'ХОЗТОВАРЫ', 'ХОЗ.НУЖДЫ Д/МАГАЗИНОВ', 'НАПИТКИ Б/А', 'СЫР',\n",
       "       'ЧАЙ,КОФЕ,КАКАО', 'ДИСКОНТНЫЕ КАРТЫ.', 'КОРМА ДЛЯ ЖИВОТНЫХ',\n",
       "       'ГРИЛЬ', 'РАСТИТЕЛЬНЫЕ МАСЛА', 'ЯЙЦО', 'СЕЗОННЫЕ ИЗДЕЛИЯ',\n",
       "       'ПРОДОВОЛЬСТВЕННЫЕ ТОВАРЫ', None], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выводим список уникальных значений в наименованиях основных групп товаров\n",
    "df['Тип_1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3b3aba-7ed1-4c48-a7a6-d9075f6cf788",
   "metadata": {},
   "source": [
    "В этом списке у нас исключаются такие группы как:\n",
    "- `УЦЕНКА/СПИСАНИЕ НЕКОНДИЦИИ`;\n",
    "- `ЛИШНЕЕ`;\n",
    "- `ДИСКОНТНЫЕ КАРТЫ.`;\n",
    "- `ХОЗ.НУЖДЫ Д/МАГАЗИНОВ`;\n",
    "- `ТАЛНАХСКАЯ 22 ПОСТОРОННИЕ ПОСТАВЩИКИ`;\n",
    "- `УСЛУГИ`;\n",
    "- `СЕЗОННЫЕ ИЗДЕЛИЯ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df923790-884c-425c-8116-4928debab319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем список наименований групп для удаления\n",
    "trash_groups = [\n",
    "    'УЦЕНКА/СПИСАНИЕ НЕКОНДИЦИИ', 'ЛИШНЕЕ', 'ДИСКОНТНЫЕ КАРТЫ.',\n",
    "    'ХОЗ.НУЖДЫ Д/МАГАЗИНОВ', 'ТАЛНАХСКАЯ 22 ПОСТОРОННИЕ ПОСТАВЩИКИ',\n",
    "    'УСЛУГИ', 'СЕЗОННЫЕ ИЗДЕЛИЯ'\n",
    "]\n",
    "\n",
    "# Фильтруем датафрейм через маску\n",
    "df = df[\n",
    "    ~df['Тип_1'].isin(trash_groups)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6fe712-1bb6-444e-a83c-33a8f8b69f12",
   "metadata": {},
   "source": [
    "Убедимся что лишние группы были удалены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c65837c6-24b8-4012-97d2-7410cd960073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Количество строк, содержащих удаляемые наименования в группе\n",
    "df['Тип_1'].isin(trash_groups).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3779282-bd38-4d7d-bf62-353e927538f7",
   "metadata": {},
   "source": [
    "### 1.4.3 Агрегация по родительской группе"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec1395e-d70b-4744-ad0a-f1d966fffb35",
   "metadata": {},
   "source": [
    "Прогноз выполняется для каждой из основных групп товаров поля `Тип_1`, поэтому при группировке по этому столбцу суммируем значения следующих полей:\n",
    "- `'Количество'`;\n",
    "- `'Сумма продажи'`;\n",
    "- `'Прибыль'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79dacf2e-9fce-471e-9df6-2b4edbb62017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем поля, по которым будет выполнятьяс группировка\n",
    "groupby_columns = ['Период, месяц', 'Тип_1']\n",
    "\n",
    "# Группируем исходный датафрейм\n",
    "df = df.groupby(\n",
    "    groupby_columns,\n",
    "    as_index=False\n",
    ")[cols_purpose].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fbd60d-18ef-4186-86de-ffa3f857ab25",
   "metadata": {},
   "source": [
    "## 1.5 Сохранение результа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06e61348-49f4-4c2d-9d7d-bf897403bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Имя файла готового результата\n",
    "output_file_name = \"Продажи.csv\"\n",
    "\n",
    "# Расположение файла\n",
    "file_save_path = work_dir / output_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "868b286e-e7ea-43f3-94a2-6a8124d1d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем в `csv` файл\n",
    "df.to_csv(\n",
    "    file_save_path,\n",
    "    sep='\\t',\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
